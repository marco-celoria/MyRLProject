{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/deep-q-network-with-pytorch-and-gym-to-solve-acrobot-game-d677836bda9b\n",
    "# https://github.com/eugeniaring/Medium-Articles/blob/main/Pytorch/acrobot.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf63ec",
   "metadata": {},
   "source": [
    "## 1: Install and Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym==0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28763a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "from collections import deque,namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install piglet\n",
    "!pip install pygame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd9f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "from gym.wrappers import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50f67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800462c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(3)\n",
      "Box([ -1.        -1.        -1.        -1.       -12.566371 -28.274334], [ 1.        1.        1.        1.       12.566371 28.274334], (6,), float32)\n"
     ]
    }
   ],
   "source": [
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937ffb8",
   "metadata": {},
   "source": [
    "## 2: Instantiate environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17117269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(3)\n",
      "Box([ -1.        -1.        -1.        -1.       -12.566371 -28.274334], [ 1.        1.        1.        1.       12.566371 28.274334], (6,), float32)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('Acrobot-v1')\n",
    "env.seed(0)\n",
    "\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0612e5f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrap_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcrobot-v1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_env\u001b[49m(env, video_callable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m episode_id: \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m): \n\u001b[1;32m      6\u001b[0m     state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wrap_env' is not defined"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('Acrobot-v1') # Initialize the Gym environment\n",
    "env.seed(0) # Set a random seed for the environment (reproducible results)\n",
    "\n",
    "# Get the shapes of the state space (observation_space) and action space (action_space)\n",
    "state_space_dim = env.observation_space.shape[0]\n",
    "action_space_dim = env.action_space.n\n",
    "\n",
    "print(f\"STATE SPACE SIZE: {state_space_dim}\")\n",
    "print(f\"ACTION SPACE SIZE: {action_space_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a445a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13467da",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7919417",
   "metadata": {},
   "source": [
    "## 3: Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    mp4list.sort()\n",
    "    for mp4 in mp4list:\n",
    "        print(f\"\\nSHOWING VIDEO {mp4}\")\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    \n",
    "def wrap_env(env, video_callable=None):\n",
    "    env = Monitor(env, './video', force=True, video_callable=video_callable)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Acrobot-v1')\n",
    "env.seed(0)\n",
    "env = wrap_env(env, video_callable=lambda episode_id: True)\n",
    "\n",
    "for num_episode in range(10): \n",
    "    # Reset the environment and get the initial state\n",
    "    state = env.reset()\n",
    "    # Reset the score. The final score will be the total amount of steps before the pole falls\n",
    "    score = 0\n",
    "    done = False\n",
    "    # Go on until the pole falls off or the score reach 490\n",
    "    while not done and score > -500:\n",
    "      # Choose a random action\n",
    "      action = random.choice([0, 1, 2])\n",
    "      # Apply the action and get the next state, the reward and a flag \"done\" that is True if the game is ended\n",
    "      next_state, reward, done, info = env.step(action)\n",
    "      # Visually render the environment (optional, comment this line to speed up the simulation)\n",
    "      env.render()\n",
    "      # Update the final score (-1 for each step)\n",
    "      score += reward \n",
    "      # Set the current state for the next iteration\n",
    "      state = next_state\n",
    "      # Check if the episode ended (the pole fell down)\n",
    "    # Print the final score\n",
    "    print(f\"EPISODE {num_episode + 1} - FINAL SCORE: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80630368",
   "metadata": {},
   "source": [
    "## 4: DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8d4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        # Define a queue with maxlen \"capacity\"\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, next_state, reward):\n",
    "        # Add the tuple (state, action, next_state, reward) to the queue\n",
    "        self.memory.append((state, action, next_state, reward))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch_size = min(batch_size, len(self)) # Get all the samples if the requested batch_size is higher than the number of sample currently in the memory\n",
    "        # Randomly select \"batch_size\" samples and return the selection\n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory) # Return the number of samples currently stored in the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "522157e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, state_space_dim, action_space_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "                  nn.Linear(state_space_dim,64),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(64,64*2),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(64*2,action_space_dim)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9325ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action_epsilon_greedy(net, state, epsilon):\n",
    "    \n",
    "    if epsilon > 1 or epsilon < 0:\n",
    "        raise Exception('The epsilon value must be between 0 and 1')\n",
    "                \n",
    "    # Evaluate the network output from the current state\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        state = torch.tensor(state, dtype=torch.float32) # Convert the state to tensor\n",
    "        net_out = net(state)\n",
    "\n",
    "    # Get the best action (argmax of the network output)\n",
    "    best_action = int(net_out.argmax())\n",
    "    # Get the number of possible actions\n",
    "    action_space_dim = net_out.shape[-1]\n",
    "\n",
    "    # Select a non optimal action with probability epsilon, otherwise choose the best action\n",
    "    if random.random() < epsilon:\n",
    "        # List of non-optimal actions (this list includes all the actions but the optimal one)\n",
    "        non_optimal_actions = [a for a in range(action_space_dim) if a != best_action]\n",
    "        # Select randomly from non_optimal_actions\n",
    "        action = random.choice(non_optimal_actions)\n",
    "    else:\n",
    "        # Select best action\n",
    "        action = best_action\n",
    "        \n",
    "    return action, net_out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6b20a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action_softmax(net, state, temperature):\n",
    "    \n",
    "    if temperature < 0:\n",
    "        raise Exception('The temperature value must be greater than or equal to 0 ')\n",
    "        \n",
    "    # If the temperature is 0, just select the best action using the eps-greedy policy with epsilon = 0\n",
    "    if temperature == 0:\n",
    "        return choose_action_epsilon_greedy(net, state, 0)\n",
    "    \n",
    "    # Evaluate the network output from the current state\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        state = torch.tensor(state, dtype=torch.float32)\n",
    "        net_out = net(state)\n",
    "\n",
    "    # Apply softmax with temp\n",
    "    temperature = max(temperature, 1e-8) # set a minimum to the temperature for numerical stability\n",
    "    softmax_out = nn.functional.softmax(net_out/temperature, dim=0).cpu().numpy()\n",
    "                \n",
    "    # Sample the action using softmax output as mass pdf\n",
    "    all_possible_actions = np.arange(0, softmax_out.shape[-1])\n",
    "    # this samples a random element from \"all_possible_actions\" with the probability distribution p (softmax_out in this case)\n",
    "    action = np.random.choice(all_possible_actions,p=softmax_out)\n",
    "    \n",
    "    return action, net_out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8784c947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Exploration profile (Softmax temperature)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Define exploration profile\n",
    "initial_value = 5\n",
    "num_iterations = 1000\n",
    "exp_decay = np.exp(-np.log(initial_value) / num_iterations * 6) # We compute the exponential decay in such a way the shape of the exploration profile does not depend on the number of iterations\n",
    "exploration_profile = [initial_value * (exp_decay ** i) for i in range(num_iterations)]\n",
    "\n",
    "### Plot exploration profile\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(exploration_profile)\n",
    "plt.grid()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Exploration profile (Softmax temperature)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b70ca1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE SPACE SIZE: 6\n",
      "ACTION SPACE SIZE: 3\n"
     ]
    }
   ],
   "source": [
    "### Create environment\n",
    "env = gym.make('Acrobot-v1') # Initialize the Gym environment\n",
    "env.seed(0) # Set a random seed for the environment (reproducible results)\n",
    "\n",
    "# Get the shapes of the state space (observation_space) and action space (action_space)\n",
    "state_space_dim = env.observation_space.shape[0]\n",
    "action_space_dim = env.action_space.n\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"STATE SPACE SIZE: {state_space_dim}\")\n",
    "print(f\"ACTION SPACE SIZE: {action_space_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "### PARAMETERS\n",
    "gamma = 0.99   # gamma parameter for the long term reward\n",
    "replay_memory_capacity = 10000   # Replay memory capacity\n",
    "#lr = 1e-2   # Optimizer learning rate\n",
    "#lr = 1e-4\n",
    "lr = 1e-3\n",
    "target_net_update_steps = 10   # Number of episodes to wait before updating the target network\n",
    "batch_size = 256   # Number of samples to take from the replay memory for each update\n",
    "bad_state_penalty = 0   # Penalty to the reward when we are in a bad state (in this case when the pole falls down) \n",
    "min_samples_for_training = 1000   # Minimum samples in the replay memory to enable the training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the replay memory\n",
    "replay_mem = ReplayMemory(replay_memory_capacity)    \n",
    "\n",
    "### Initialize the policy network\n",
    "policy_net = DQN(state_space_dim, action_space_dim).to(device)\n",
    "\n",
    "### Initialize the target network with the same weights of the policy network\n",
    "target_net = DQN(state_space_dim, action_space_dim).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict()) # This will copy the weights of the policy network to the target network\n",
    "\n",
    "### Initialize the optimizer\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=lr) # The optimizer will update ONLY the parameters of the policy network\n",
    "\n",
    "### Initialize the loss function (Huber loss)\n",
    "loss_fn = nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1b5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_step(policy_net, target_net, replay_mem, gamma, optimizer, loss_fn, batch_size):\n",
    "        \n",
    "    # Sample the data from the replay memory\n",
    "    batch = replay_mem.sample(batch_size)\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    # Create tensors for each element of the batch\n",
    "    states      = torch.tensor([s[0] for s in batch], dtype=torch.float32, device=device)\n",
    "    actions     = torch.tensor([s[1] for s in batch], dtype=torch.int64, device=device)\n",
    "    rewards     = torch.tensor([s[3] for s in batch], dtype=torch.float32, device=device)\n",
    "\n",
    "    # Compute a mask of non-final states (all the elements where the next state is not None)\n",
    "    non_final_next_states = torch.tensor([s[2] for s in batch if s[2] is not None], dtype=torch.float32, device=device) # the next state can be None if the game has ended\n",
    "    non_final_mask = torch.tensor([s[2] is not None for s in batch], dtype=torch.bool)\n",
    "\n",
    "    # Compute all the Q values (forward pass)\n",
    "    policy_net.train()\n",
    "    q_values = policy_net(states)\n",
    "    # Select the proper Q value for the corresponding action taken Q(s_t, a)\n",
    "    state_action_values = q_values.gather(1, actions.unsqueeze(1).cuda())\n",
    "\n",
    "    # Compute the value function of the next states using the target network V(s_{t+1}) = max_a( Q_target(s_{t+1}, a)) )\n",
    "    with torch.no_grad():\n",
    "        target_net.eval()\n",
    "        q_values_target = target_net(non_final_next_states)\n",
    "    next_state_max_q_values = torch.zeros(batch_size, device=device)\n",
    "    next_state_max_q_values[non_final_mask] = q_values_target.max(dim=1)[0].detach()\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = rewards + (next_state_max_q_values * gamma)\n",
    "    expected_state_action_values = expected_state_action_values.unsqueeze(1)# Set the required tensor shape\n",
    "\n",
    "    # Compute the Huber loss\n",
    "    loss = loss_fn(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # Apply gradient clipping (clip all the gradients greater than 2 for training stability)\n",
    "    nn.utils.clip_grad_norm_(policy_net.parameters(), 2)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fd325b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrap_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcrobot-v1\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m) \n\u001b[0;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_env\u001b[49m(env, video_callable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m episode_id: episode_id \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Save a video every 100 episodes\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plotting_rewards\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode_num, tau \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(exploration_profile)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wrap_env' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the Gym environment\n",
    "env = gym.make('Acrobot-v1') \n",
    "env.seed(0) # Set a random seed for the environment (reproducible results)\n",
    "\n",
    "# This is for creating the output video in Colab, not required outside Colab\n",
    "env = wrap_env(env, video_callable=lambda episode_id: episode_id % 100 == 0) # Save a video every 100 episodes\n",
    "\n",
    "plotting_rewards=[]\n",
    "\n",
    "for episode_num, tau in enumerate(tqdm(exploration_profile)):\n",
    "\n",
    "    # Reset the environment and get the initial state\n",
    "    state = env.reset()\n",
    "    # Reset the score. The final score will be the total amount of steps before the pole falls\n",
    "    score = 0\n",
    "    done = False\n",
    "\n",
    "    # Go on until the pole falls off\n",
    "    while not done:\n",
    "\n",
    "        # Choose the action following the policy\n",
    "        action, q_values = choose_action_softmax(policy_net, state, temperature=tau)\n",
    "      \n",
    "        # Apply the action and get the next state, the reward and a flag \"done\" that is True if the game is ended\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Update the final score (+1 for each step)\n",
    "        score += reward\n",
    "\n",
    "        # Apply penalty for bad state\n",
    "        if done: # if the pole has fallen down \n",
    "            reward += bad_state_penalty\n",
    "            next_state = None\n",
    "      \n",
    "        # Update the replay memory\n",
    "        replay_mem.push(state, action, next_state, reward)\n",
    "\n",
    "        # Update the network\n",
    "        if len(replay_mem) > min_samples_for_training: # we enable the training only if we have enough samples in the replay memory, otherwise the training will use the same samples too often\n",
    "            update_step(policy_net, target_net, replay_mem, gamma, optimizer, loss_fn, batch_size)\n",
    "\n",
    "        # Visually render the environment (disable to speed up the training)\n",
    "        env.render()\n",
    "\n",
    "        # Set the current state for the next iteration\n",
    "        state = next_state\n",
    "\n",
    "    # Update the target network every target_net_update_steps episodes\n",
    "    if episode_num % target_net_update_steps == 0:\n",
    "        print('Updating target network...')\n",
    "        target_net.load_state_dict(policy_net.state_dict()) # This will copy the weights of the policy network to the target network\n",
    "    \n",
    "    plotting_rewards.append(score)\n",
    "    # Print the final score\n",
    "    print(f\"EPISODE: {episode_num + 1} - FINAL SCORE: {score} - Temperature: {tau}\") # Print the final score\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07a0ccee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotting_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m801\u001b[39m),\u001b[43mplotting_rewards\u001b[49m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining episodes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcc. Episodic Reward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plotting_rewards' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1612edc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrap_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcrobot-v1\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_env\u001b[49m(env, video_callable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m episode_id: \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# Save a video every episode\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plotting_rewards2\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Let's try for a total of 10 episodes\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wrap_env' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,num_iterations+1),plotting_rewards)\n",
    "plt.xlabel('Training episodes')\n",
    "plt.ylabel('Acc. Episodic Reward')\n",
    "plt.ylim([-500,-40])\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Acrobot v1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a70047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Gym environment\n",
    "env = gym.make('Acrobot-v1') \n",
    "env.seed(1) # Set a random seed for the environment (reproducible results)\n",
    "\n",
    "# This is for creating the output video in Colab, not required outside Colab\n",
    "env = wrap_env(env, video_callable=lambda episode_id: True) # Save a video every episode\n",
    "\n",
    "plotting_rewards2=[]\n",
    "# Let's try for a total of 10 episodes\n",
    "for num_episode in range(10): \n",
    "    # Reset the environment and get the initial state\n",
    "    state = env.reset()\n",
    "    # Reset the score. The final score will be the total amount of steps before the pole falls\n",
    "    score = 0\n",
    "    done = False\n",
    "    # Go on until the pole falls off or the score reach 490\n",
    "    while not done:\n",
    "      # Choose the best action (temperature 0)\n",
    "      action, q_values = choose_action_softmax(policy_net, state, temperature=0)\n",
    "      # Apply the action and get the next state, the reward and a flag \"done\" that is True if the game is ended\n",
    "      next_state, reward, done, info = env.step(action)\n",
    "      # Visually render the environment\n",
    "      env.render()\n",
    "      # Update the final score (+1 for each step)\n",
    "      score += reward \n",
    "      # Set the current state for the next iteration\n",
    "      state = next_state\n",
    "      # Check if the episode ended (the pole fell down)\n",
    "    # Print the final score\n",
    "    plotting_rewards2.append(score)\n",
    "    print(f\"EPISODE {num_episode + 1} - FINAL SCORE: {score}\") \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
